# NeuroDesk

 Chat with Ollama Models

 Uses `qwen3:latest` Models

 Todo: Make model loading dynamic.

 ## Install Ollama
 https://ollama.com

 ```bash
 ollama run qwen3:latest
 ```

## Tailwindcss

```bash

tailwindcss -i ./src/input.css -o ./css/output.css --watch

```
```bash
cargo tauri dev

```


```bash
cargo tauri build
```
